---
#
# Generic Helm chart values.yaml for deploying applications with optional database, ingress, and NFS-backed storage.
#
## ------------ General Specifications ------------ ##
#
namespace: ""

# Optional: Override the full name of the release (metadata.name).
fullnameOverride: ""

# Optional: Override just the name portion of the Helm release.
nameOverride: ""

#
## ------------ App Deployment Specifications ------------ ##
#
app:
  name: ""
  image:
    repository: ""
    tag: ""
    pullPolicy: IfNotPresent

  replicaCount: 1

  # The port the application listens on inside the container.
  containerPort: 80

  service:
    # Leave it empty to use default ClusterIP service type.
    # type: ClusterIP

    # The port exposed by the K8s Service.
    port: 80
    # The targetPort that maps to containerPort.
    targetPort: 80

  volumeMounts:
    # Mount path for the Deployment.
    ## -- `mountPath`: Pointing to the app container image volume (e.g., /app/data).
    ## -- `subPath`: Pointing to the volume on the backend PVC (e.g., /mnt/nfs/someapp/data).
    ##               The directory will be created automatically on the storage backend.
    - mountPath: ""
      subPath: ""

  # Optional (StatefulApps only):
  # Database environment variable 'name' the app uses to reference the DB hostname.
  # This enables dynamic injection of the DB hostname via Helm templating.
  # Example: ["dbhost", "DATABASE_HOST"]
  dbHostname: ""

  # Optional: List of additional environment variables the app may need.
  # Format:
  # - name: ENV_VAR_NAME
  #   value: somevalue
  env: []

  # Optional: Reference a secret to inject environment variables.
  # This assumes the secret is created separately.
  envFromSecrets:
    enabled: false
    secretRefNames: []

  # Affinity rules for app pod scheduling.
  affinity: {}

  # A naive probes to check if the container is ready. It will
  # run the target the `containerPort` defined above and run
  # against the root path ("/"). Returns 200 OK if the app is ready.
  readinessProbe:
    enabled: false

  # Liveness probe, it can be defined here.
  livenessProbe:
    enabled: false
    command: []
    initialDelaySeconds: 20
    periodSeconds: 60
    timeoutSeconds: 10
    failureThreshold: 3

#
## ------------ StatefulSet Specifications ------------ ##
#
database:
  enabled: false

  # Optional: hostname override if needed (typically injected automatically).
  host: ""

  # Port the DB pod is listening on (e.g., 3306 for MariaDB/MySQL).
  port: 3306

  image:
    # For DB images, prefer Bitnami's for NFS-friendliness.
    repository: ""
    tag: ""
    pullPolicy: IfNotPresent

  volumeMounts:
    # Mount path for the Statefulset.
    ## -- `mountPath`: Pointing to the DB container image volume (e.g., /bitnami/mariadb).
    ## -- `subPath`: Pointing to the volume on the backend PVC (e.g., /mnt/nfs/someapp/db). The directory will be created automatically on the storage backend.
    - mountPath: ""
      subPath: ""

  # DB pod's environment variables.
  # For example, use Bitnami-specific vars like MARIADB_ROOT_PASSWORD, etc.
  # Format:
  # - name: MARIADB_USER
  #   value: someuser
  env: []

  # Number of DB pod replicas
  replicas: 1

  # Affinity rules for db pod scheduling.
  affinity: {}

#
## ------------ Storage Specifications ------------ ##
#
#
# If you have an existing PersistentVolumeClaim. To be shared by app + db.
# Otherwise, use `nfs-persistent-volume` to create a new PVC.
# Each container will mount their subPaths within this PVC.
existingClaim: ""

#
# Configuration for creating a new PersistentVolumeClaim using NFS backend.
# If `existingClaim` is provided, this section will be ignored.
#
# Note: The 'storage' size spec below is not enforced by the NFS CSI driver.
# It only serves as metadata for K8s to match PVCs for scheduling/quota
# calculations. Storage limit depends on the available space or quotas configured on the NFS server itself.
persistence:
  enabled: false

  # Optional name: defaults to the app/release name if not provided.
  name: ""

  # Size of the volume claim. E.g. 10Gi, 50Gi, etc. (see note above)
  size: 1Gi
  accessMode: ReadWriteMany
  reclaimPolicy: Retain

  # Optional: Specify an existing storage class name for dynamic PV provisioning.
  storageClassName: ""

  # NFS server details
  nfs:
    # NFS server IPv4 e.g. 10.20.6.5
    server: ""
    # Path in the NFS share e.g. /mnt/nfs/unichart
    path: ""

#
## ------------ Ingress Specifications ------------ ##
#
ingress:
  enabled: true

  # Hostname for external access
  host: ""

  # IngressClass to use (e.g., "nginx", "traefik", etc.)
  ingressClassName: "nginx"

  # The port to expose via ingress (typically 80 or 443).
  port: 80

  # Extra annotations for the ingress resource.
  # Example for cert-manager:
  # annotations:
  #   cert-manager.io/cluster-issuer: "letsencrypt-prod"
  annotations: {}
